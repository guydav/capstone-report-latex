Children increase their efficiency at learning new tasks or skills with related prior experience \parencite{Brown1988a}. Machine learning researchers have been interested in developing approaches that mimic this human capacity for \emph{meta-learning}. Existing research (e.g., \cite{Santoro2016}; \cite{Finn2017}; \cite{Mishra2018}) evaluates algorithms by examining the level of performance attained on new problems given limited data, using few-shot classification as a prototypical test problem. We offer a different metric, inspired by \textcite{Thrun1996}, investigating how algorithms scale in sample complexity as a function of the number of previous tasks learned, and a second metric examining how catastrophic interference varies by expertise on a particular task or within a domain. We introduce a new meta-learning image dataset inspired by CLEVR \textcite{Johnson2017} and a computer vision task setting for answering yes/no questions about objects in an image. We demonstrate that a baseline model with no specialized architecture shows some meta-learning capacity, learning to acquire tasks faster, but at the cost of higher interference for later tasks. We show that a second model, utilizing query-based modulation of visual processing, learns slightly faster and without substantially lower catastrophic interference.
