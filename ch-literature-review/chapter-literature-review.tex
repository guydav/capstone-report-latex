\chapter{Literature Review\label{ch:literature-review}}
The previous section introduced the problem this work investigates, both describing why scaling behavior and catastrophic forgetting are meaningful problems to examine in the context of meta-learning, and making the argument that the meta-learning literature currently does not focus on these concerns. To provide additional context, this section will review different meta-learning approaches. We will review meta-learning approaches for different types of learning problems (supervised learning, reinforcement learning, or others) and discuss the model architectures or learning procedures they implement. Beyond meta-learning, we will survey the continual/lifelong learning literature, which does tend to examine catastrophic forgetting when evaluating models, and visual question answering work, which inspired our dataset and task design. We do not aim to provide a comprehensive review and exhaustively cover the field, but instead, introduce a more extensive array of approaches to contextualize this work better.

\section{Model-Independent Algorithms}
One set of meta-learning algorithms are entirely independent of the model architecture, instead offering learning procedures that allow augmenting any model with meta-learning capacities. This approach was spearheaded by model-agnostic meta-learning (MAML; \cite{Finn2017}), who propose splitting each training iteration in two stages, an update, which takes a training step optimizing for solving a particular task, and a meta-update, which combines a number of updates into a training step which should improve performance on a collection of these tasks simultaneously. Their motivation is to find model parameters which are “sensitive to changes in the task,” allowing to optimize for a new task in a minimal number of updates. The authors continue exploring these ideas in future publications (\cite{Finn2018a}; \cite{Grant2018}), taking on a probabilistic perspective and considering their algorithm through the lens of hierarchical Bayesian modeling, as learning the prior distribution for model parameters over a set of tasks. The authors report experiments on toy regression problems, few-shot classification problems such as mini-ImageNet, as well as a few simple reinforcement learning settings.
 
The perspective of meta-learning as learning an effective weight initialization for a distribution of tasks is not unique to MAML. \textcite{Fernando2018} describe a Baldwinian-evolution based approach to meta-learning, which attempts to learn such a weight initialization through a genetic approach optimization to minimize the amount of training required to learn new tasks. \textcite{Nichol} introduce a simplified version of MAML, which does not use two separate learning stages (thus avoiding the computationally-expensive second-order gradient needed for the latter stage), and propose a second, simpler approach. Both of these authors also focus their empirical results on few-shot classification.

\section{Reinforcement Learning and Recurrence-Based Algorithms}
Some of the earlier work in meta-learning focused on using recurrence as the computational enabler of learning how to learn. This line of work originates from \textcite{Hochreiter2001}, who demonstrated how a recurrent neural network could exhibit meta-learning dynamics using nothing more than gradient descent and appropriately shaped task data, which at every timestep includes the current input the predict and the correct output for the previous input, enabling learning. \textcite{Andrychowicz2016} build on this approach and attempt to explicitly learn an optimizer, which they formulate using a recurrent neural network, and use this learned optimizer to control the learning of another model, demonstrating that their learned optimizers outperform standard, hard-coded ones. \textcite{Finn2018} provide evidence that MAML can also approximate a wide variety of learning algorithms, suggesting multiple different approaches can recover this behavior.

Recurrence-based approaches have also proved to be popular in reinforcement learning settings, where they allow to adaptively modify the learned policy for different tasks. \textcite{Wang2016} introduce this line of work by defining deep meta-reinforcement learning, using deep reinforcement learning algorithms to train a recurrent model, which can then adapt to new tasks solely through the recurrent dynamics, without requiring additional weight updates. \textcite{Duan2017} explore similar ideas, which \textcite{Ritter2018,Ritter2018a} extend by introducing an external memory unit, allowing the model to identify previously-solved tasks and immediately recall the learned solutions. \textcite{Houthooft2018} take a vastly different approach to meta-reinforcement learning, using an evolutionary optimization procedure to learn a loss function, which is then used to optimize the reinforcement learning model. This learned loss function allows the reinforcement learning model to better optimize for long-term success, rather than short-term results, providing impressive meta-learning results by learning new tasks flexibly and rapidly.

\section{Few-shot Image Classification}
Few-shot image classification serves as one of the primary measures used to evaluate meta-learning approaches, and although most approaches to this problem do not involve meta-learning (at least not explicitly), we deem them worth reviewing. As described above, few-shot learning involves attempting to learn to discriminate between some number of classes, based on a limited number of features, with the eventual goal of being able to learn categories from a single exemplar, as humans can \parencite{Lake2015}. \textcite{Lake2015,Lake2019} introduced Omniglot, a handwritten character dataset designed for this task, which includes twenty examples of each of 1623 unique characters, from fifty different alphabets. \textcite{Vinyals2016} developed the other dataset widely used for these models, mini-ImageNet, in which they take a limited subset of ImageNet \parencite{Deng2009}, offering fewer examples per class and fewer classes than the full ImageNet. 

Approaches taken to this problem vary greatly, and so we will review a few. \textcite{Lake2015} presented Bayesian Program Learning, which learns a generative, stroke-based model of the handwritten characters. \textcite{Vinyals2016} proposed Matching Networks, which learn an attention-based classifier for each class using a small number of examples. \textcite{Hariharan2016} suggest a novel loss function which helps learn representations that are more conducive to few-shot learning. \textcite{Shyam2017} use a recurrent model with attention to repeatedly glimpse between two images and compare them, using these comparisons to classify. \textcite{Snell2017} learn a metric space conducive to few-shot classification, and \textcite{Triantafillou2017} take an information-theoretical perspective to this problem. 

\section{Visual Question Answering}
Visual question answering (VQA) is task paradigm and dataset introduced by \textcite{Antol2015} and expanded on by \textcite{Agrawal2016}, which serves as inspiration for the task designed in this work. VQA is fundamentally an understanding problem, which seeks to challenge computer vision models beyond what image classification could: if a model truly understands an image, it should be able to reason about, beyond merely labeling it.  \textcite{Agrawal2016} describe a variety of methods, including a model closely resembling the baseline model we will use, \textcite{Andreas2015,Andreas2016} take an approach based on module networks, defining a variety of modules a priori, and learning to parameterize instances of each one based on the query. \textcite{Hu2016,Hu2017} extend this work by explicitly learning compositional relationships between entities and simplifying the training procedure. \textcite{Johnson} also build on this line of work, changing the module architecture to be more generic, rather than specified in advance. 

CLEVR \parencite{Johnson2017} is another, similar dataset, designed for Compositional Language and Elementary Visual Reasoning. The authors present artificially rendered images, using the 3D modeling software Blender \parencite{BlenderOnlineCommunity2018}, where each image includes several objects, each object identified by a color, shape, texture, and size. The authors introduced this dataset to examine how models perform on a variety of different question types, focusing on relational questions, which require relative reasoning between objects in the images. One notable recent approach to CLEVR is FiLM \parencite{Perez2017,Dumoulin2018}, Feature-wise Linear Modulation, which modifies the visual representations based on the current question asked, a form of conditioned normalization. Our query-based modulation approach is a simpler, independently developed operationalization of similar ideas.

\section{Cognitive Influences: Relational Reasoning, Memory, Attention}
Several different influences from cognition made their way into different models for meta-learning, visual question answering, and other related problems. \textcite{Santoro} introduce Relational Networks, which explicitly evaluate relations between pairs of objects and reason about them. They also propose the Sort-of-CLEVR task, which also helped inform our task design. \textcite{Santoro2018} expand on this work and develop recurrent relational models, using a Relational Memory Core, which allows the network to encode memories in a fashion that enables to reason over them in relational terms. Several other approaches also employ different forms of memory. \textcite{Santoro2016} use episodic memory to achieve meta-learning by learning to encode and retrieve relevant information to aid in generalizing to new tasks. \textcite{Ritter2018} employ memory to augment the meta-reinforcement learning approach of \textcite{Wang2016}, by retaining a context to each previously solved task and recalling solutions based on these contexts. \textcite{Munkhdalai2018} utilize an external memory, and a combination of fast and slow weights (not unlike Yuan et al., 2017) in order to attain meta-learning behavior. 

Attention-based mechanisms also show widespread usage in deep neural networks, for a similar variety of problem. \textcite{Xu2015} use attention in order to perform image captioning, allowing the model to focus on different parts of input images as it describes them. \textcite{Kahou2017} combine recurrence and attention in order to allow a model to track objects between successive related input images. \textcite{Chen} do not explicitly refer to attention, but introduce a gating model, which controls which parts of the main model are active; this gating process can be interpreted as attentional selection. \textcite{Vaswani2017} introduce the attention mechanism employed by \textcite{Santoro2018}, a generic form of self-attention allowing a model to prioritize different components of its representation at different depths. \textcite{Mishra2018} operationalize attention for meta-learning by allowing a model to perform temporal convolutions over previous inputs and weigh them using an attentional mechanism biased on the current task. 

\section{Lifelong/Continual Learning}
\textcite{Thrun1995} coined the term lifelong learning, also referred to as continual learning, seeking to emulate the wide variety of different yet related learning problems humans face through their lifetime, and encourage artificial learning in similar settings. \textcite{Goodfellow2015} evaluate several different neural networks modifications in a continual learning setting, measuring catastrophic forgetting between tasks, discovering that adding dropout appears beneficial in reducing the effect of forgetting, presumably as they require the network to learn redundancy due to the stochasticity of dropout. \textcite{Parisi2019} provide a recent review of this field, describing an array of lifelong learning models and architectures, as well as some of the benchmarks used to evaluate models. \textcite{Lopez-Paz2017} formalize the notions of forgetting and transfer as forwards and backward transfer, where negative backward transfer implies catastrophic interference, while positive forwards transfer indicates successful transfer learning. \textcite{Kemker2017a} review some evaluation methods, examining data permutation experiments, multimodal learning, and incremental class learning, which most closely resembles one of the benchmarks we will propose. 

A wide array of approaches to augmenting models to overcome catastrophic forgetting exists. \textcite{Kirkpatrick2017} introduce elastic weight consolidation, which adds a penalty to the model loss, encouraging not changing weights that most contribute to successfully solving previous tasks. \textcite{Lopez-Paz2017} describe Gradient Episodic Memory, which retains examples of previous tasks and minimizes the aforementioned negative backward transfer. \textcite{Kemker2018} devise FearNet, a neurally-inspired model with dual-memory design, using consolidation mechanisms modeled after mammalian sleep consolidation. \textcite{Zenke2017} are similarly biologically-inspired, motivating intelligent synapses which track their relevance to particular tasks, not unlike \possessivecite{Kirkpatrick2017} approach. \textcite{Kamra2017} offer another dual-memory model, augmenting with a generative replay model able to recreate past experiences and improve performance on previously learned tasks. 

