\section{Machine Learning}
\begin{itemize}
\item \textbf{Algorithm (learning algorithm):\label{tg:algorithm}} a machine learning algorithm is a set of steps for how to learn to solve a particular machine learning problem given appropriate data. Many different algorithms could be used to solve the same problem, and the same algorithm could be applicable to a single problem, or to a variety of problem. Machine learning research often attempts to propose and evaluate algorithms to solve particular tasks. Examples include linear regression, support vector machines (SVM), naive Bayes classifiers, and deep neural networks, which this work focuses on. This \href{https://skymind.ai/wiki/machine-learning-algorithms}{\emph{tutorial}} describes a large variety of different machine learning algorithms.

\item \textbf{AUC ROC (Area Under the Curve of the Receiver Operating Characteristic curve):\label{tg:auc}} a standard measure of classification models considered more robust and holistic than the accuracy. The ROC plots the true positive rate (which we hope is high) against the false positive rate (which we hope is low) for different decision thresholds between predicting `yes' and predicting `no' (in the binary classification case). To summarize this curve as a single number, we compute the area under it (by integrating). A perfect model would have an AUC of 1.0, while a perfectly wrong model would score 0.0. See \href{https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc}{\emph{this entry}} from Google's Machine Learning Crash Course for additional details.

\item \textbf{Batch (mini-batch):\label{tg:batch}} When we have sufficiently large amounts of data, we cannot always pass the entire dataset through the model simultaneously. This means that the model is only trained on a subset of the examples in the dataset at each iteration, and therefore, \hyperref[tg:weights]{weight} (see below) updates only reflect that subset of the data. Batch size is a tradeoff: updating the model after every single image is usually too slow, and the \hyperref[tg:gradient]{gradients} (see below) don't represent the population well. Training on the entire training set is usually infeasible due to limitations (usually on the GPU RAM). Choosing a batch size is more art than science, although ``as large as fits in memory'' is one good heuristic. Usually sampled without replacement from the entire training set.

  \begin{itemize}
  \item \textbf{Epoch:\label{tg:epoch}} When training in batches, an epoch is considered to be one pass through the entire training set, after which the model might be evaluated on held-out data (see training set and test set below) and its parameters saved.
  \end{itemize}
  
\item \textbf{Continual/lifelong learning:\label{tg:lifelong-learning}} lifelong (or continual) learning is the machine learning subfield that looks to mimic human learning in the capacity to continue learning over a long period of time, particularly one including multiple tasks (in a supervised learning setting) or changes to the environment (in a reinforcement learning context). The aim is the ability to continue learning as the world and tasks change without losing all previously acquired knowledge. See this \href{https://www.cs.uic.edu/~liub/lifelong-learning.html}{\emph{longer description}} or this \href{https://www.darpa.mil/news-events/2017-03-16}{\emph{DARPA program}} for additional details.
  \begin{itemize}
  \item \textbf{Catastrophic interference:\label{tg:catastrophic}} is one of the key problems in lifelong learning settings. If no effort to the contrary is taken, models tend to forget previous tasks once they are no longer trained on, as default update procedures (such as backpropagation) optimize to solve currently trained problems, without an attempt to preserve previously acquired solutions. This term originally comes from the \hyperref[tg:connectionist]{connectionist models} (see below) literature, and see this \href{https://rylanschaeffer.github.io/content/research/overcoming_catastrophic_forgetting/main.html}{\emph{blog post}} for a longer description.
  \end{itemize}
  
\item \textbf{Connectionist models:\label{tg:connectionist}} also known as parallel distributed processing (PDP) models, the precursor to current neural network and deep learning models. This modeling approach came to prominence in the psychology literature in the 1980's, and attempted to model psychological phenomena by specifying learning rules operating over small groups of individual units, which conceptually map to neurons or neuron groups, creating an artificial neural network (ANN). See this \href{https://www.iep.utm.edu/connect/}{\emph{Internet Encyclopedia of Psychology entry}} for additional details.

\item \textbf{Deep learning:\label{tg:deep-learning}} the modern version of connectionist models, creating artificial neural networks that are substantially larger than the ones of yesteryear, particularly in depth (the number of layers in the model), but also in the overall size of each layer. Due to their size, they require both substantially more computational resources and larger amounts of data to successfully fit to problems. See \href{https://skymind.ai/wiki/neural-network\#concept}{\emph{this tutorial}} for additional details on deep neural networks and many of the concepts covered below.

\item \textbf{Embedding (sometimes also called latent representation):\label{tg:embedding}} an embedding is an alternative representation for some input data that models can more easily reason over, usually also in a lower-dimensional space than an input. For instance, the default binary representation for words saves each letter as a separate set of binary digits, which means words have varying lengths, and that the words ``cat'' and ``car'' differ slightly even though their meaning is vastly different. Embedding approaches attempt to find fixed-size representations that preserve important characteristics of the input (for instance, semantic meaning) in a way that models can compute properties with. See \href{https://developers.google.com/machine-learning/crash-course/embeddings/obtaining-embeddings}{\emph{this tutorial}} from Google's Machine Learning Crash Course for additional details and examples.

\item \textbf{Graphics processing unit (GPU):\label{tg:gpu}} graphics cards that were originally developed for, well, graphics purposes, are currently often used to accelerate the performance of deep learning algorithms, as both graphics applications and deep learning require performing large matrix multiplications rapidly. A model may often run ten to one hundred times faster using a GPU than on a computer's regular process, the central processing unit (CPU). See additional details on this \href{http://timdettmers.com/2018/11/05/which-gpu-for-deep-learning/}{\emph{blog post}}.

\item \textbf{Gradient (and gradient descent):\label{tg:gradient}} a multivariable generalization of the derivative. In machine learning contexts, often used for optimization. The gradient of a function at a point is the direction in which it it maximally increases for all of its input variables. Given some \hyperref[tg:loss]{loss function} (see below) we attempt to minimize, we can do so by computing the loss function over one or more data points, and update the model by taking a small step in opposite direction to the gradient, which points us toward the maximally decreasing direction. See \href{https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html}{\emph{this entry}} in the machine learning cheatsheet website for additional details

  \begin{itemize}
  \item \textbf{Stochastic gradient descent (SGD):\label{tg:sgd}} the `stochastic' part reflects the fact that if we have sufficiently large amounts of data, we cannot pass them all through the model (to compute the loss and gradient) at the same time, and therefore must divide the data into batches. The gradient of each batch is an approximation of the gradient of the entire dataset, to the extent each batch reflects the entire dataset well (and isn't, say, biased towards particular types of examples). Note that stochastic gradient descent is sometimes discussed for individual examples (batches of size one), and for larger batches, it might be referred to as mini-batch gradient descent. See this \href{http://ruder.io/optimizing-gradient-descent/index.html\#stochasticgradientdescent}{\emph{blog post}} for a fantastically long description of different gradient-descent based algorithms.
  
  \end{itemize}
\item \textbf{Labeled data:\label{tg:labeled-data}} the type of data required to train \hyperref[tg:supervised]{supervised learning algorithms} (see below), where each example $X^i$ is associated with a correct answer $y^i$, usually a scalar. Examples include images and each image's category for image classification problems, the correct function value in regression problems, or a set of an image, a question, and the correct answer to that question on that image in visual question answering (VQA) settings).

  \begin{itemize}
  \item \textbf{Weakly labeled:\label{tg:weakly-labeled}} data which includes a label, but that label may not be perfectly correct, or not be the type of label required for the supervised learning problem trained. An example from one of the research papers referenced \parencite{Mahajan2018} uses Instagram hash-tags to help train an image classification model, which to be supervised requires a single correct label, while hash-tags might not be perfectly accurate.
  
  \item \textbf{Unlabeled data:\label{tg:unlabeled}} the data used to train \hyperref[tg:unsupervised]{unsupervised} learning algorithms (see below), which includes only examples $X^i$, \emph{without} corresponding labels $y^i$. The
  
  \end{itemize}
\item \textbf{Loss function:\label{tg:loss}} a function that serves as the objective to be optimized by a machine learning model, mapping the output of the model and the correct answer to a scalar number specifying how well the model did on that example, where the optimal loss is zero. Common choices include the cross-entropy function in classification and the mean squared error in regression. See this \href{https://blog.algorithmia.com/introduction-to-loss-functions/}{\emph{blog post}} for additional exposition and examples.

  \begin{itemize}
  \item \textbf{Cross-entropy:\label{tg:cross-entropy}} this loss function is most often used in classification settings, and penalizes the model when it fails to assign all probability mass to the correct answer. If we denote the correct probabilities as $p(x)$, and the models predictions as $q(x)$, then the cross entropy loss is $L(x) = - \sum\_x p(x) \log q(x)$. In classification settings, the correct answer is assigning all probability mass to the true class of the image, and the cross-entropy loss becomes $L(x) = - \log q(x_c)$, where $x_c$ is the true label of the image. This quantity is minimized, as we would expect, at $q(x_c) = 1$, and any $q(x) < 1$ incurs a loss. \href{https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html}{\emph{This entry}} in the Machine Learning cheat sheet discusses this and other loss functions at greater length.
  \end{itemize}
  
\item \textbf{Meta-learning:\label{tg:meta-learning}} a machine-learning subfield interested in the problem of learning to learn, broadly defined. In standard learning problems we provide a learning algorithm with a single task, and examine how quickly and accurately the model can learn the task. In meta-learning, we provide a distribution of related tasks, and examine how well a model can learn \emph{how to learn} the individual tasks. A meta-learning algorithm attempts to learn and adjust the learning process for each individual problem. This \href{https://medium.com/huggingface/from-zero-to-research-an-introduction-to-meta-learning-8e16e677f78a}{\emph{Medium post}} provides additional details and reviews some research.

  \begin{itemize} 
  \item \textbf{Episode:\label{tg:episode}} in the context of meta-learning, an episode is a round of training on a single task, where the model receives data corresponding to the current task and attempts to train on it.
  
  \item \textbf{Task:\label{tg:task}} the individual problems a meta-learning model tries to solve. One common benchmark is few-shot learning, in which a model receives a small number of images for a new class and needs to learn to discriminate that class from others. In regular image classification settings, the model might see thousands of images in each class, hundreds of times each; in this setting the model is exposed to a few examples and a few times each.
  \end{itemize}
  
\item \textbf{Model:\label{tg:model}} a machine learning model is the application of a machine learning \hyperref[tg:algorithm]{algorithms} (see above) to a particular dataset in attempt to solve a problem. It could be completely off-the-shelf (taking widely available code and applying it to a problem) or heavily modified, but either way, it is an algorithm trained on a dataset for a particular task.

\item \textbf{Reinforcement learning:\label{tg:reinforcement-learning}} a learning setting where a model interacts with an environment by taking actions, and receives a scalar reward signal, which is usually sparse, that is, not every action taken leads to a reward. Games are often modeled as reinforcement learning problems, where the reward (or punishment) comes at the end of a game, based on whether the model won or lost. See \href{https://skymind.ai/wiki/deep-reinforcement-learning}{\emph{this tutorial}} for a longer description or these \href{http://web.stanford.edu/class/cs234/slides/lnotes_intro.pdf}{\emph{detailed notes}} from Stanford's CS234 course.

\item \textbf{Representation (feature learning, representation learning):\label{tg:representation}} The form of the input that we humans use to reason about it might not match the form of the input a machine learning model requires or develops. In classical computer vision approaches, models often used the Histogram of Oriented Gradients (HOG; see \href{https://www.learnopencv.com/histogram-of-oriented-gradients/}{\emph{this tutorial}}) as the input for a model to reason over. Neural networks usually do not require this sort of feature engineering, instead learning to develop useful latent representations through the course of training. When we discuss the representation a network learns for an input, we refer to the pattern of activations at a particular layer when that input is fed through a network. See \href{http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/}{\emph{this tutorial}} in the supervised learning, convolutional neural networks context, and \href{http://ufldl.stanford.edu/tutorial/selftaughtlearning/SelfTaughtLearning/}{\emph{this tutorial}} in an unsupervised context.

\item \textbf{Supervised learning:\label{tg:supervised}} a learning problem where a model attempts to provide the correct output for an image. These problems require \hyperref[tg:labeled-data]{labeled data} (see above), and the model is trained using these labels: if model attempts to classify images as cats or dogs, it might predict an image is 70\% likely to be a dog, and correspondingly 30\% likely to be a cat. It will then receive the correct answer (perhaps a cat, in this case), and adjust its \hyperref[tg:weights]{parameters} (see below) accordingly. See additional details on this \href{https://medium.com/machine-learning-for-humans/supervised-learning-740383a2feab}{\emph{Medium post}}. There are two primary types of supervised learning problems:
  \begin{itemize}
  \item \textbf{Classification:\label{tg:classification}} in classification problems, each input (following the above example, an image) is associated with one or more (but usually one) class. The model attempts to learn to predict the correct label (cat or dog) for each image.
  
  \item \textbf{Regression:\label{tg:regression}} in regression problems, each input is associated with a numeric output (often a scalar, but sometimes a vector). The model attempts to predict the correct value for each input. An example might be predicting the market value (the output) of an apartment based on various factors (the input), such as the number of bedrooms, which floor it is on, its size, and so forth.
  \end{itemize}
  
\item \textbf{Training set and test set:\label{tg:training-test}} when training a model, we wish to verify it successfully learned a problem, rather than memorized the training examples or found some particularly of them. We therefore split our dataset into two parts, a larger training set (usually between 75\% to 95\% of the data) and smaller test set. The training set is used for fitting the model, and it is allowed to learn from the mistakes it makes on it and update its \hyperref[tg:weights]{weights} (see below). The test set is only used to evaluate the model -\/- it is never provided with the correct answers and allowed to learn from them.

  \begin{itemize}
  \item \textbf{Generalization:\label{tg:generalization}} successfully learning from the training set, and performing well on the held-out test set. Ideally, a model will perform equally well on the test set as it does on the training set, which shows it managed to learn the task well. See \href{https://developers.google.com/machine-learning/crash-course/generalization/video-lecture}{\emph{this video}} from Google's Machine Learning Crash Course for an explanation of generalization and overfitting.
  
  \item \textbf{Overfitting:\label{tg:overfitting}} the opposite of successful generalization, overfitting is the case where a model continues improving on the training set, without improving (or worse, losing performance) on the test. Overfitting is a point where a model starts learning nuances of the training set that do not apply to the test set, rather than learning the features and structures shared between the two sets.
  
  \item \textbf{Validation set:\label{tg:validation}} in cases where there are \hyperref[tg:hyperparameters]{hyperparameters} (see below) to be chosen, beyond the learned parameters, the data is often split in three ways, introducing a validation set between the training and test sets. The training set is then usually used to train models with various hyperparameter settings, which are evaluated based on the performance on the validation set, rather than making selections according to the performance on the test set.
  \end{itemize}
  
\item \textbf{Transfer learning:\label{tg:transfer}} a machine learning subfield, this problem offers a learning paradigm that attempts to explicitly transfer knowledge from one problem to another, in order to better solve problems with little \hyperref[tg:labeled-data]{labeled data} (see above) available. The broad approach is to train a model on a problem for which high amounts of labeled data are available, and then fine-tune the model on the target problem for which little data is available. This \href{http://ruder.io/transfer-learning/}{\emph{longform post}} provides a thorough introduction to the problem.

\item \textbf{Unsupervised learning:\label{tg:unsupervised}} a machine learning subfield interested in learning without \hyperref[tg:labeled-data]{labeled data} (see above), usually by extracting some sort of structure from data. Examples include clustering (group data points by some underlying similarity), anomaly detection (which of these things is unlike the others), or autoencoders (encode the input to some smaller, latent representation, and attempt to decode back the original input. This \href{https://blog.algorithmia.com/introduction-to-unsupervised-learning/}{\emph{blog post}} provides additional information and examples.

\item \textbf{Weights (parameters):\label{tg:weights}} machine learning \hyperref[tg:algorithm]{algorithms} (see above) include a set parameters or weights which are adapted according to the data, rather than specified in advance. In regression problems, these would be the coefficients weighting each of the input values in order to predict an output value. In neural networks, these are the connection strengths from each \hyperref[tg:layer]{layer's} (see below) inputs to its outputs, or the particular filters used by a \hyperref[tg:cnn]{convolutional neural network} (see below). See this \href{https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/}{\emph{blog post}} for a discussion of parameters, hyperparameters, and differences between them.

  \begin{itemize}
  \item \textbf{Hyperparameters:\label{tg:hyperparameters}} some machine learning algorithms also include parameters that cannot be directly learned from data as the weights can, but whose values will impact the performance of the algorithm on a problem. These often includes values governing the learning process, of the sort that \hyperref[tg:meta-learning]{meta-learning} (see above) might attempt to learn. These are usually determined by training models with different hyperparameters values and comparing them on a held-out \hyperref[tg:validation]{validation set} (see above).
  \end{itemize}
\end{itemize}